# Multilingual RAG Backend - API Documentation & System Design

## ğŸ§© Overview

This backend is a **FastAPI-based** system supporting multilingual **Retrieval-Augmented Generation (RAG)** for question answering over user-uploaded documents. It supports:

- User registration & authentication
- PDF document upload
- Embedding and vector storage
- Contextual querying with Gemini LLM
- Chat history retrieval

---

## ğŸ“˜ API Documentation

### Root Endpoint

```http
GET /
```

Returns:

```json
{ "msg": "Multilingual RAG backend running" }
```

---

### ğŸ” Auth APIs

#### POST `/auth/signup`

Create a new user and send their autogenerated username to email.

**Flow:**

- User provides **email** and **password**.
- System checks if email already exists.
- If not, a unique **username** is generated.
- The username is sent to the provided email.
- User is informed to check email for username.

Request Body:

```json
{
  "email": "user@example.com",
  "password": "secure-password"
}
```

Response:

```json
{
  "msg": "User created. Username has been sent to your email."
}
```

#### POST `/auth/token`

Login using **username** and **password** (not email).

**Flow:**

- User enters **username** and **password**.
- If credentials are correct, system issues a JWT token.
- If incorrect, it returns an error.

Form Data:

```
username=...&password=...
```

Response:

```json
{
  "access_token": "jwt-token",
  "token_type": "bearer"
}
```

If login fails:

```json
{
  "detail": "Incorrect username or password"
}
```

#### GET `/auth/user`

Get the logged-in user's profile.

Authorization: `Bearer <token>`

Response:

```json
{
  "username": "user-1a2b3c4d",
  "email": "user@example.com"
}
```

---

### ğŸ“¤ Upload APIs

#### POST `/upload/`

Upload a PDF file for embedding and vector storage.

Headers:

- Authorization: Bearer token

Form Data:

- `file`: PDF

Response:

```json
{ "msg": "File uploaded and processed" }
```

---

### ğŸ’¬ Chat APIs

#### POST `/chat/`

Query documents and get a Gemini-generated answer.

Request Body:

```json
{ "query": "What is quantum computing?" }
```

Headers:

- Authorization: Bearer token

Response:

```json
{ "answer": "Quantum computing is... thanks for asking!" }
```

#### GET `/chat/history`

Get previous chat logs for the authenticated user.

Response:

```json
[
  { "query": "What is AI?", "answer": "AI is..." },
  ...
]
```

---

## ğŸ§  How RAG Works

**Retrieval-Augmented Generation Flow:**

1. **Document Upload**:

   - PDF is uploaded via `/upload/`
   - Content is split into pages
   - Full content is embedded using Gemini Embedding API
   - Embedding + content is stored in MongoDB

2. **User Query**:

   - User submits a query via `/chat/`
   - Query is embedded
   - Similarity search is done against stored document embeddings (cosine similarity)
   - Top-k matching contents are retrieved
   - These are passed as context to Gemini LLM
   - Gemini generates an answer based on context + question

### ğŸ” Diagram - RAG Flow

```text
[User] â”€â”¬â”€> /upload â”€â”€â”€> [Extract Text + Embed] â”€â”€â”€> [MongoDB: Store Embeddings]
        â”‚
        â””â”€> /chat â”€â”€â”€> [Embed Query] â”€> [Vector Search] â”€> [Top-K Context]
                                     â””â”€> [Gemini LLM] â”€â”€> [Response]
```

---

## ğŸ›ï¸ System Design (High Level)

### ğŸ“¦ Architecture Components

```
[ FastAPI App ]
  â”œâ”€â”€ Auth API          â”€ user creation, login, JWT
  â”œâ”€â”€ Upload API        â”€ document upload
  â”œâ”€â”€ Chat API          â”€ contextual Q&A via Gemini
  â”œâ”€â”€ MongoDB           â”€ users, chats, documents (with embeddings)
  â”œâ”€â”€ Emailer           â”€ email generated username
  â”œâ”€â”€ Gemini Embedding  â”€ document/query embedding
  â”œâ”€â”€ Gemini LLM        â”€ answer generation
```

### ğŸŒ External Dependencies

- Google Gemini Embedding + Chat API
- MongoDB (cloud or local)
- SMTP for sending welcome emails

---

## âš™ï¸ System Design (Low Level)

### Components:

- `main.py`: Mounts routers, configures CORS
- `auth.py`: Handles signup, login, user fetch
- `chat.py`: RAG pipeline and chat history
- `upload.py`: Stores embedded PDFs
- `vector.py`: Embeds + stores document vectors
- `gemini.py`: Defines prompt + calls Gemini
- `embedder.py`: Embeds text via Gemini
- `mongo.py`: Vector search and persistence

### MongoDB Collections:

- `users`: { username, email, hashed\_password }
- `chats`: { username, query, answer }
- `documents`: { username, content, embedding }

---

## Diagram 

### System Architecture

<img width="3617" height="3846" alt="Untitled diagram _ Mermaid Chart-2025-07-24-060116" src="https://github.com/user-attachments/assets/e2ab6f69-71f2-47f3-9f58-fcd8fdfd7083" />

### Component Interaction

<img width="1186" height="373" alt="Component Interface" src="https://github.com/user-attachments/assets/5ffda8a5-2d16-4b85-a4c3-d4b5867a17fa" />

---

## ğŸ”’ Auth Flow

- User signs up with **email** and **password**.
- Backend generates a unique **username** (e.g., `user-1a2b3c4d`).
- Sends the username to the user via email.
- User then logs in using **username** + **password** (not email).
- Passwords hashed via `bcrypt`
- Token generated via JWT (HS256)
- Token passed via `Authorization: Bearer <token>`
- Login fails with HTTP 400 if credentials are invalid.

---

## ğŸ› ï¸ Technologies Used

- **FastAPI** â€“ API framework
- **MongoDB** â€“ vector + user storage
- **Gemini LLM** â€“ embeddings & responses
- **Langchain** â€“ wrapper around Gemini
- **scikit-learn** â€“ cosine similarity

---

## ğŸ§ª Testing & Docs

Once deployed, docs are available at:

```
GET /docs  # Swagger UI
GET /redoc # ReDoc
```

---

## ğŸ“¦ Deployment

- Dockerized via `Dockerfile`
- Run with:

```bash
docker build -t rag-backend .
docker run -p 8000:8000 rag-backend
```
